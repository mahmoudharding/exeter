{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e8aa5c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab07.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5256f7e0",
   "metadata": {},
   "source": [
    "# Lab 07: Modeling and Estimation with Loss Functions\n",
    "\n",
    "Welcome to Lab 07! In this lab you will implement a basic model, define loss functions, and minimize loss functions using numeric libraries. \n",
    "\n",
    "To receive credit for a lab, answer all questions correctly and submit before the deadline.\n",
    "\n",
    "**Due Date:** \n",
    "\n",
    "**Collaboration Policy:** Data science is a collaborative activity. While you may talk with others about the labs, we ask that you **write your solutions individually**. If you do discuss the assignments with others **please include their names below** (it's a good way to learn your classmates' names).\n",
    "\n",
    "**Collaborators:** \n",
    "\n",
    "List collaborators here.\n",
    "\n",
    "Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630b1f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aaaacc",
   "metadata": {},
   "source": [
    "# 0. Loading the Tips Dataset\n",
    "\n",
    "To begin with, we load the `tips` dataset from the `seaborn` library.  The `tips` data contains records of tips, total bill, and information about the person who paid the bill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f06871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset(\"tips\")\n",
    "\n",
    "print(\"Number of Records:\", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0a264d",
   "metadata": {},
   "source": [
    "# 1. Constant Model and Loss Functions\n",
    "\n",
    "## Constant Model\n",
    "\n",
    "In the modeling context, $y$ represents our \"true observations\", which are typically what we are trying to model. $\\hat{y}$ (pronounced y \"hat\") represents our prediction for any model. In this lab, we will use the constant model, where our prediction for any input is a constant:\n",
    "\n",
    "$$\\hat{y} = c$$\n",
    "\n",
    "$c$ is what we call a **parameter**. Our goal is to find the value of our parameter(s) that **best fit our data**. We represent the optimal parameter(s) with $\\hat{\\theta}$.\n",
    "\n",
    "We call the constant model a **summary statistic**, as we are determining one number that best \"summarizes\" a set of values.\n",
    "\n",
    "\n",
    "## Loss Functions\n",
    "\n",
    "Loss functions are what we use to determine the optimal parameter(s) for our model. A loss function is a measure of how well a model is able to predict the expected outcome. In other words, it measures the deviations of the predicted values from the observed values. In the formulations below $y$ represents the observed values and $\\hat{y}$ stands for our prediction.\n",
    "\n",
    "- **Squared Loss** (also known as the $L_2$ loss, pronounced \"ell-two\") $L(y, \\hat{y}) = (y - \\hat{y})^2$\n",
    "\n",
    "\n",
    "- **Absolute Loss** (also known as the $L_1$ loss, pronounced \"ell-one\") $L\\left(y, \\hat{y} \\right) = \\left| y - \\hat{y} \\right|$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac22f41",
   "metadata": {},
   "source": [
    "# 2. Squared Loss Function\n",
    "\n",
    "$$L\\left(y,\\theta \\right)=\\left(y-\\theta \\right)^2$$\n",
    "\n",
    "**Question 1.** Based on the comments below, implement the squared loss function on the constant model $\\hat{y}=c$. \n",
    "\n",
    "**Note:** Your answer should not use any loops.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a4056a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def squared_loss(y_obs, c):\n",
    "    \"\"\"\n",
    "    Purpose\n",
    "    -------\n",
    "    Calculate the squared loss of the observed data and a summary statistic.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_obs: An observed value\n",
    "    c:     A constant representing a summary statistic\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The squared loss between the observation and the summary statistic.\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab71b864",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bc6140",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2.** Let us now consider the case where `y_obs` equals 10. For arbitrary values of `c`, plot the squared loss using the function you implemented in the previous question. Don't forget to label your graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eebc849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_obs = ...\n",
    "\n",
    "# arbitrary values of theta\n",
    "c_values = np.linspace(0, 20, 100)\n",
    "\n",
    "# plot\n",
    "plt.xlabel(r\"Choice for $c$\")\n",
    "plt.ylabel(r\"...\")\n",
    "plt.plot(..., ...);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ce99fe",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# 3. Average Loss\n",
    "\n",
    "Our main concern is how \"good\" or how \"bad\" the model's predictions are for an entire data set, not just one observation. The average loss of a model \n",
    "\n",
    "$$\\frac{1}{n}\\sum\\limits_{i=1}^n L(y_i,\\hat{y}_i)$$ \n",
    "\n",
    "is a measure of how well the model \"fits\" the data. \n",
    "\n",
    "If squared loss is the loss function, then the average squared loss is referred to as mean squared error (MSE), and is of the following form \n",
    "\n",
    "$$\\text{MSE}(y,\\hat{y})=\\frac{1}{n}\\sum\\limits_{i=1}^n (y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "If absolute loss is the loss function, then the average absolute loss is referred to as mean absolute error (MAE), and is of the following form \n",
    "\n",
    "$$\\text{MAE}(y,\\hat{y})=\\frac{1}{n}\\sum\\limits_{i=1}^n |y_i-\\hat{y}_i|$$\n",
    "\n",
    "where \n",
    "\n",
    "- $n$: Number of data values.\n",
    "\n",
    "- $i$: $i$th value in a data set.\n",
    "\n",
    "- $y_i$: Value for $i$th datum.\n",
    "\n",
    "- $\\hat y_i$: Prediction for $i$th datum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0542e4be",
   "metadata": {},
   "source": [
    "Let's apply our knowledge to some real world data. In section **0. Loading the Tips Dataset** we loaded the `tips` dataset from the `seaborn` package.\n",
    "\n",
    "In this section, you will try to find the best statistic $c$ to represent the tips given in the array. The simple procedure you will use in this lab includes constructing the mean squared error (MSE) for the tips data and finding the value that minimizes the MSE.\n",
    "\n",
    "**Question 3.** Make an array named `tips` using the `tip` column from the `df` dataframe that was loaded in **Section 0. Loading the Tips Dataset**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b05a71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tips = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e639978",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0264eb1e",
   "metadata": {},
   "source": [
    "Now, we can extend the above loss functions to an entire dataset by taking the average. Let the dataset $D$ be the set of observations:\n",
    "\n",
    "$$D = \\{y_1, \\ldots, y_n\\}$$\n",
    "\n",
    "where $y_i$ is the $i^{\\text{th}}$ tip.\n",
    "\n",
    "We can define the average loss over the dataset as:\n",
    "\n",
    "$$R\\left(c\\right)=\\frac{1}{n} \\sum_{i=1}^n L(y_i, c)$$\n",
    "\n",
    "**Question 4.** Define the `mean_squared_error` function which computes the mean squared error given the data and a value for `c`. Assume that `data` will be a `numpy` array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab14bf4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(c, data):\n",
    "    \"\"\"\n",
    "    Purpose\n",
    "    -------\n",
    "    Calculate the mean square error.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    c: A constant representing a summary statistic\n",
    "    data: A numpy array of data values\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The value of the mean square error.\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6f9fdf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4b3991",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 5.** In the cell below plot the mean squared error for different `c` values. Note that `c_values` are given. Make sure to label the axes on your plot. And remember to use the `tips` variable we defined earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d83e92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_values = np.linspace(0, 6, 100)\n",
    "mse = ...\n",
    "\n",
    "plt.xlabel(r\"Choice for $c$\")\n",
    "plt.ylabel(r\"...\")\n",
    "plt.plot(..., ...);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920bd5a5",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 6.** Find the value of `c` that minimizes the $L_2$ loss above via observation of the plot you've generated. Round your answer to the nearest integer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29514d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_observed_mse = ...\n",
    "min_observed_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323b9765",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c570420",
   "metadata": {},
   "source": [
    "## Find the Minimizing Value for Our Tips Dataset\n",
    "\n",
    "The cell below plots some arbitrary 4$^\\text{th}$ degree polynomial function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e64d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = np.linspace(-4, 2.5, 100)\n",
    "\n",
    "def fx(x):\n",
    "    return 0.1 * x**4 + 0.2*x**3 + 0.2 * x **2 + 1 * x + 10\n",
    "\n",
    "plt.plot(x_values, fx(x_values));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffffc4db",
   "metadata": {},
   "source": [
    "By looking at the plot, we see that the $x$ which minimizes the function is slightly larger than $-2$. What if we want the exact value?\n",
    "\n",
    "The function `minimize` from [`scipy.optimize`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) will attempt to minimize a function. Try running the cell below, and you will see that minimize seems to get the answer correct.\n",
    "\n",
    "**Note:** For this lab, we'll just use the `minimize` function. We'll discuss how `minimize` works later in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09b9fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "minimize(fx, x0 = 1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a689b86",
   "metadata": {},
   "source": [
    "The `fun` value is the minimum value of the function. The `x` is the $x$ which minimizes the function. We can index into the object returned by `minimize` to get these values. We have to add the additional `[0]` at the end because the minimizing $x$ is returned as an array, but this is not necessarily the case for other attributes (i.e., `fun`). The reason for this is that `minimize` can also minimize multivariable functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972ec373",
   "metadata": {},
   "source": [
    "The parameter `x0` that we passed to the `minimize` function is where the `minimize` function starts looking as it tries to find the minimum. For example, above, `minimize` started its search at $x = 1.1$ because that's where we told it to start. For the function above, it doesn't really matter what $x$ we start at because the function has only a single global minimum. More technically, the function is [convex](https://en.wikipedia.org/wiki/Convex_function), a property of functions that we will discuss later in the course.\n",
    "\n",
    "Alas, `minimize` isn't perfect. For example, if we give it a function with many valleys (also known as local minima) it can get stuck. For example, consider the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71266980",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_values = np.linspace(-2, 10, 100)\n",
    "\n",
    "def fw(w):\n",
    "    return 0.1 * w**4 - 1.5*w**3 + 6 * w **2 - 1 * w + 10\n",
    "\n",
    "plt.plot(w_values, fw(w_values));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f700c84",
   "metadata": {},
   "source": [
    "If we start the minimization at $w = 6.5$, we'll get stuck in the local minimum at $w = 7.03$. \n",
    "\n",
    "**Note:** No matter what your actual variable is called in your function, the `minimize` routine still calls the starting point `x0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ab0bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize(fw, x0 = 6.5)['x'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e179d33d",
   "metadata": {},
   "source": [
    "**Question 7.** Using the `minimize` function, find the value of `theta` that minimizes the mean squared error for our tips dataset. In other words, you want to find the exact minimum of the plot that you generated in **Question 5**.\n",
    "\n",
    "Assign `min_sq_scipy` to the value of `c` that minimizes the MSE according to the `minimize` function.\n",
    "\n",
    "You can't pass your `mean_squared_error` function to `minimize` because `mean_squared_error` has two variables: `c` and `data`. `minimize` will get confused because it thinks it needs to minimize by picking the best `c` and best `data` values. We only want it to use `c`.\n",
    "\n",
    "Therefore, you need to pass a function of one variable, `c`, to the `minimize` function. This means you'll need to create a new function of only **one** variable `c`. In practice this is simple, but it can also be very tricky when you do this for the first time. Make sure to ask for help if you get stuck.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e9f66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_squared_error_with_one_variable(c):\n",
    "    \"\"\"\n",
    "    Purpose\n",
    "    -------\n",
    "    Calculate the mean square error with one variable.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    c: A constant representing a summary statistic \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The value of the mean square error.\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "min_sq_scipy = minimize(..., x0 = ...)[...][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e1b572",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668374f2",
   "metadata": {},
   "source": [
    "**Question 8.** The value of `c` that minimizes the mean squared error is the average of the data for the constant model. Assign `min_sq_computed` to the mean of the tips dataset, and compare this to the values you observed in **Questions 5.** and **Question 7**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146eb6b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_sq_computed = ...\n",
    "min_sq_computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d92a8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f604ec20",
   "metadata": {},
   "source": [
    "Reflecting on the lab so far, we've now seen 3 ways to find the summary statistic `c` that minimizes the mean squared error:\n",
    "\n",
    "1. Create a plot of the MSE for the given data array vs. `c` and eyeball the minimizing `c`.\n",
    "\n",
    "2. Create a function that returns the MSE for a specific data array as a function of `c` and use the scipy `minimize` function to find the exact `c` which minimizes this function.\n",
    "\n",
    "3. Simply compute the `mean` of the data array.\n",
    "\n",
    "At this point, you've hopefully convinced yourself that the `mean` of the data is the summary statistic that minimizes mean squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef0efe3",
   "metadata": {},
   "source": [
    "# 3. Absolute Loss Function \n",
    "\n",
    "$$L\\left(y, c \\right) = \\left| y - c \\right|$$\n",
    "\n",
    "In this section, you will follow the exact same steps as above but for the absolute loss function.\n",
    "\n",
    "**Question 9.** In the cell below define the function `abs_loss` which returns the absolute loss given a value of `c` and `y_obs`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b009fff7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def abs_loss(y_obs, c):\n",
    "    \"\"\"\n",
    "    Purpose\n",
    "    -------\n",
    "    Calculate the absolute loss of the observed data and a summary statistic.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_obs: an observed value\n",
    "    c: A constant representing a summary statistic\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The absolute loss between the observation and the summary statistic.\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8369e04",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ff50c1",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 10.** Let us now consider the case where `y_obs` equals 10. For arbitrary values of `c`, plot the absolute loss using the function you implemented in the previous question. Don't forget to label your graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d07b3e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_obs = ...\n",
    "\n",
    "# arbitrary values of theta\n",
    "c_values = np.linspace(0, 20, 100)\n",
    "\n",
    "# plot\n",
    "plt.xlabel(r\"Choice for $c$\")\n",
    "plt.ylabel(r\"...\")\n",
    "plt.plot(..., ...);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfcfec2",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 11.** Define the `mean_absolute_error` function which computes the mean absolute error given the data and a value for `c`. Assume that `data` will be a `numpy` array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b7232",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_absolute_error(c, data):\n",
    "    \"\"\"\n",
    "    Purpose\n",
    "    -------\n",
    "    Calculate the mean absolute error.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    c: A constant representing a summary statistic\n",
    "    data: A numpy array of data values\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The value of the mean absolute error.\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0c1aeb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c1e0f1",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 12.** In the cell below plot the mean absolute error for different `c` values on the `tips` dataset. Note that `theta_values` are given. Make sure to label the axes on your plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35edd41b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_values = np.linspace(0, 6, 100)\n",
    "mae = ...\n",
    "\n",
    "plt.xlabel(r\"Choice for $c$\")\n",
    "plt.ylabel(r\"...\")\n",
    "plt.plot(..., ...);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0fb8b9",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "You should see that the plot looks somewhat similar the plot of the mean squared error. However, there are three key differences that we identified between the plots of the MSE and MAE.\n",
    "\n",
    "1. The minimizing $c$ is different.\n",
    "\n",
    "2. The plot for MAE increases linearly instead of quadratically as we move far away from the minimizing $c$.\n",
    "\n",
    "3. The plot for MAE is piecewise linear instead of smooth. Each change in slope happens at the same $c$ value as a data point in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453f1c54",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 13.** To minimize the function, let's zoom in closer to the graph to get a better idea of the value of the minimizing `c`. Plot the mean absolute error again using the given `c_values` below. Don't forget to label your axes.\n",
    "\n",
    "**Note:** You will need to generate the list of `mae` values again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0c602b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_values = np.linspace(2.7, 3.02, 100)\n",
    "mae = ...\n",
    "\n",
    "plt.xlabel(r\"Choice for $c$\")\n",
    "plt.ylabel(r\"...\")\n",
    "plt.plot(..., ...);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea077b97",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "This time, observe that the function is piecewise linear and has a slope of zero near its minimum. Because of the large flat region at the minimum, there are multiple values of `c` that minimize the $L_1$ loss.\n",
    "\n",
    "**Question 14.** Give a `theta` rounded to the nearest tenth that minimizes $L_1$ loss. By \"rounded to the nearest tenth\" we mean you'd say 7.6 instead of 7.55.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b0662c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_observed_mae = ...\n",
    "min_observed_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56823457",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7013ff",
   "metadata": {},
   "source": [
    "# 4. Find the Minimizing Value for the Tips Dataset \n",
    "\n",
    "**Question 15.** As before, we will use the `minimize` function to find a solution. Assign `min_abs_scipy` to the value of `c` that minimizes the MAE according to the `minimize` function for the `tips` data. \n",
    "\n",
    "**Note:** Depending on the `x0` value you specify, you will get different results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445bab9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_absolute_error_with_one_variable(c):\n",
    "    \"\"\"\n",
    "    Purpose\n",
    "    -------\n",
    "    Calculate the mean absolute error with one variable.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    c: A constant representing a summary statistic \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The value of the mean absolute error.\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "min_abs_scipy = minimize(..., x0 = ...)[...][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bef18c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78659f21",
   "metadata": {},
   "source": [
    "Just like the MSE, there are three ways to compute the summary statistic `c` that minimizes the MAE:\n",
    "\n",
    "1. Create a plot of the MAE for the given data array vs. `c` and eyeball a minimizing `c`.\n",
    "\n",
    "2. Create a function that returns the MAE for a specific data array as a function of `c` and use the scipy `minimize` function to find an exact `c` which minimizes this function.\n",
    "\n",
    "3. Simply compute the ... of the data array.\n",
    "\n",
    "Try to figure out what to substitute in for the ... above. To this, try out various statistics functions provided by `np`. Click [here](https://docs.scipy.org/doc/numpy/reference/routines.statistics.html) to view the `numpy` documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05ce93d",
   "metadata": {},
   "source": [
    "**Question 16.** Assign `min_abs_computed` to the correct summary statistic using method `3` from the previous problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5460e7ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_abs_computed = ...\n",
    "min_abs_computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e6c74d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095de7f7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a7152",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a66bf9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "When done exporting, download the .zip file by `SHIFT`-clicking on the file name and selecting **Save Link As**. Or, find the .zip file in the left side of the screen and right-click and select **Download**. You'll submit this .zip file for the assignment in Canvas to Gradescope for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ebab4e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fdb32e",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> y = np.array([0.1,0.2,0.3,0.4,0.5])\n>>> round(sum(squared_loss(y, 0.5)), 1)\n0.3",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q11": {
     "name": "q11",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 < round(mean_absolute_error(9, tips), 1) < 7\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q14": {
     "name": "q14",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 < min_observed_mae < 3\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q15": {
     "name": "q15",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 < min_abs_scipy < 3\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q16": {
     "name": "q16",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 < min_abs_computed < 5\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(tips, np.ndarray)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> len(tips)\n244",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.sum(tips)\n731.5799999999999",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> round(mean_squared_error(9, tips), 1)\n37.9",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 < min_observed_mse < 5\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 < min_sq_scipy < 3\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8": {
     "name": "q8",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 < min_sq_computed < 3\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9": {
     "name": "q9",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> y = np.array([0.1,0.2,0.3,0.4,0.5])\n>>> round(sum(abs_loss(y, 0.5)), 1) == 1.0\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
