{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b550427",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab07.ipynb\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62ed2c69",
   "metadata": {},
   "source": [
    "## Lab 07: Modeling and Estimation with Loss Functions\n",
    "\n",
    "Welcome to Advanced Topics in Data Science for High School! Throughout the course you will complete assignments like this one. You can't learn technical subjects without hands-on practice, so these assignments are an important part of the course.\n",
    "\n",
    "**Collaboration Policy:**\n",
    "\n",
    "Collaborating on labs is more than okay -- it's encouraged! You should rarely remain stuck for more than a few minutes on questions in labs, so ask a neighbor or an instructor for help. Explaining things is beneficial, too -- the best way to solidify your knowledge of a subject is to explain it. You should **not** _just_ copy/paste someone else's code, but rather work together to gain understanding of the task you need to complete. \n",
    "\n",
    "**Due Date:**\n",
    "\n",
    "## Today's Assignment \n",
    "\n",
    "In today's assignment, you'll learn about:\n",
    "\n",
    "* mean loss functions\n",
    "\n",
    "* absolute loss functions\n",
    "\n",
    "First, set up the imports by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7078dea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb78c41d",
   "metadata": {},
   "source": [
    "## 1. Loading the Tips Dataset\n",
    "\n",
    "To begin with, we load the `tips` dataset from the `seaborn` library.  The `tips` data contains records of tips, total bill, and information about the person who paid the bill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54c2dab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = sns.load_dataset(\"tips\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97f6f0b0",
   "metadata": {},
   "source": [
    "## 2. The Constant Model and Loss Functions\n",
    "\n",
    "### Constant Model\n",
    "\n",
    "In the modeling context, $y$ represents our \"true observations\", which are typically what we are trying to model. $\\hat{y}$ (pronounced y \"hat\") represents our prediction for any model. In this lab, we will use the constant model, where our prediction for any input is a constant:\n",
    "\n",
    "$$\\hat{y} = \\theta$$\n",
    "\n",
    "$\\theta$ is what we call a **parameter**. Our goal is to find the value of our parameter that **best fits our data**. We represent the optimal parameter with $\\hat{\\theta}$.\n",
    "\n",
    "We call the constant model a **summary statistic**, as we are determining one number that best \"summarizes\" a set of values.\n",
    "\n",
    "### Loss Functions\n",
    "\n",
    "Loss functions are what we use to determine the optimal parameter for our model. A loss function is a measure of how well a model is able to predict the expected outcome. In other words, it measures the deviations of the predicted values from the observed values. In the formulations below $y$ represents the observed values and $\\theta$ stands for our prediction.\n",
    "\n",
    "- **Absolute Loss** (also known as the $L_1$ loss, pronounced \"ell-two\") is $L_1\\left(\\theta, y \\right) =  \\left| y -\\theta \\right|$\n",
    "\n",
    "- **Squared Loss** (also known as the $L_2$ loss, pronounced \"ell-two\") is $L_2(\\theta, y) = (y - \\theta)^2$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5366f3ec",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Squared Loss Function\n",
    "\n",
    "$$L\\left(\\theta , y \\right)=\\left(y- \\theta \\right)^2$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd73ba13",
   "metadata": {},
   "source": [
    "**Question 1.** Based on the comments in the document string in the function below, implement the squared loss function on the constant model $\\hat{y}=\\theta$. \n",
    "\n",
    "**Note:** Your answer should not use any loops.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532af6fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def squared_loss(y_i, theta):\n",
    "    \"\"\"\n",
    "    Purpose\n",
    "    -------\n",
    "    Calculate the squared loss of the observed data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_i: An array of observed values\n",
    "    theta: A constant representing a summary statistic\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The squared loss between the observation and the summary statistic\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59e8b785",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Make sure that you verify that your function (`squared_loss`) is correct before moving on to the next question."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a90b0b7",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2.** Let us now consider the case where `theta` equals 10. For arbitrary values of `y_is`, plot the squared loss using the function you implemented in the previous question. Don't forget to label your graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef02f59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Our choice for theta\n",
    "theta = ...\n",
    "\n",
    "# Array of values for y_i\n",
    "y_is = np.linspace(0, 20, 100)\n",
    "\n",
    "# Plot\n",
    "plt.xlabel(...)\n",
    "plt.ylabel(...)\n",
    "plt.plot(..., ...);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b824abf8",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "You should notice that the value of $\\theta$ is the mean of the `y_is` array. It is the location of vertex of a parabola that is concave up. \n",
    "\n",
    "Run the cell below to verify. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91285cbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.mean(y_is)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c61fa0bb",
   "metadata": {},
   "source": [
    "### Average Loss\n",
    "\n",
    "Our main concern is how \"good\" or how \"bad\" the model's predictions are for an entire data set, not just one observation. The average loss of a model \n",
    "\n",
    "$$\\frac{1}{n}\\sum\\limits_{i=1}^n L(\\theta, y_i)$$ \n",
    "\n",
    "is a measure of how well the model \"fits\" the data. \n",
    "\n",
    "If squared loss is the loss function, then the average squared loss is referred to as mean squared error (MSE), and is of the following form \n",
    "\n",
    "$$\\text{MSE}(\\theta, y)=\\frac{1}{n}\\sum\\limits_{i=1}^n (y_i-\\theta)^2$$\n",
    "\n",
    "If absolute loss is the loss function, then the average absolute loss is referred to as mean absolute error (MAE), and is of the following form \n",
    "\n",
    "$$\\text{MAE}(\\theta, y)=\\frac{1}{n}\\sum\\limits_{i=1}^n |y_i-\\theta|$$\n",
    "\n",
    "where \n",
    "\n",
    "- $n$:      Number of data values.\n",
    "\n",
    "- $i$:      $i$th value in a data set.\n",
    "\n",
    "- $y_i$:    Value for $i$th datum.\n",
    "\n",
    "- $\\theta$: A constant representing a summary statistic."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b95a8b6",
   "metadata": {},
   "source": [
    "Let's apply our knowledge to some real world data. In section **Loading the Tips Dataset** we loaded the `tips` dataset from the `seaborn` package.\n",
    "\n",
    "In this section, you will try to find the best summary statistic $\\hat \\theta$ to represent the tips given in the array. The simple procedure you will use in this lab includes constructing the mean squared error (MSE) for the tips data and finding the value that minimizes the MSE."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c0ed04a",
   "metadata": {},
   "source": [
    "**Question 3.** Make a `NumPy` array named `tips` using the `tip` column from the `df` dataframe that was loaded in section entitled **Loading the Tips Dataset**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a605906",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tips = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5107b683",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b588516f",
   "metadata": {},
   "source": [
    "Now, we can extend the above loss functions to an entire dataset by taking the average. Let the dataset $D$ be the set of observations:\n",
    "\n",
    "$$D = \\{y_1, \\ldots, y_n\\}$$\n",
    "\n",
    "where $y_i$ is the $i^{\\text{th}}$ tip.\n",
    "\n",
    "We can define the average loss over the dataset as:\n",
    "\n",
    "$$L\\left(\\theta, y\\right)=\\frac{1}{n} \\sum_{i=1}^n l(\\theta, y_i)$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ed47c36",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 4.** Define the `mean_squared_error` function which computes the mean squared error given the data as an array and a value for `theta`. \n",
    "\n",
    "**Note:** Assume that `data` will be a `NumPy` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a9df6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(data, theta):\n",
    "    \"\"\"\n",
    "    Purpose\n",
    "    -------\n",
    "    Calculate the mean square error\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data:  An array of data values\n",
    "    theta: A constant representing a summary statistic\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The value of the mean square error\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36247605",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 5.** Choose three values for $\\theta$. Then use the `mean_squared_error` function with the `tips` data to see which of your choices for $\\theta$ has the least loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d2a4b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Our choice for theta\n",
    "theta_1 = ...\n",
    "theta_2 = ...\n",
    "theta_3 = ...\n",
    "print(\"The loss for theta_1 is\", mean_squared_error(tips, theta_1))\n",
    "print(\"The loss for theta_1 is\", mean_squared_error(tips, theta_2))\n",
    "print(\"The loss for theta_1 is\", mean_squared_error(tips, theta_3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33a8e18e",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 6.** Which one of your values for $\\theta$ in the previous question had the least loss? Why do you think this was the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a6423c",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adcfb529",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "In the cell below we plot the mean square error for different $\\theta$ values on the `tips` dataset. You should save your mean squared error estimates in a list named `mse`.\n",
    "\n",
    "**Note:** The `theta_values` are given. Make sure to label the axes on your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6ce7ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "theta_values = np.linspace(1, 5, 100)\n",
    "mse = [mean_squared_error(tips, t) for t in theta_values] \n",
    "\n",
    "plt.xlabel(r\"Choice for $\\theta$\")\n",
    "plt.ylabel(r\"Mean Square Error\")\n",
    "plt.plot(theta_values, mse);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c7353e2",
   "metadata": {},
   "source": [
    "You should notice that the minimum value of MSE looks like it occurs somewhere around 3, the average of the `tips` dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af939dc6",
   "metadata": {},
   "source": [
    "### Find the Minimizing Value for Our Tips Dataset\n",
    "\n",
    "The cell below plots some arbitrary 4$^\\text{th}$ degree polynomial function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7c5b92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_values = np.linspace(-4, 2.5, 100)\n",
    "\n",
    "def fx(x):\n",
    "    return 0.1 * x**4 + 0.2*x**3 + 0.2 * x **2 + 1 * x + 10\n",
    "\n",
    "plt.plot(x_values, fx(x_values));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af51ff1d",
   "metadata": {},
   "source": [
    "By looking at the plot, we see that the $x$ which minimizes the function is slightly larger than $-2$. What if we want the exact value?\n",
    "\n",
    "[The function `minimize` from `scipy.optimize`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) will attempt to minimize a function. Run the cell below to verify that minimize seems to get the answer correct.\n",
    "\n",
    "**Note:** For this lab, we'll just use the `minimize` function. We'll discuss how `minimize` works later in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b665426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "minimize(fx, x0 = 1.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebee2e23",
   "metadata": {},
   "source": [
    "The `fun` value is the minimum value of the function. The `x` is the $x$ which minimizes the function. We can index into the object returned by `minimize` to get these values. We have to add the additional `[0]` at the end because the minimizing $x$ is returned as an array, but this is not necessarily the case for other attributes (i.e., `fun`). The reason for this is that `minimize` can also minimize multivariable functions.\n",
    "\n",
    "The parameter `x0` that we passed to the `minimize` function is where the `minimize` function starts looking as it tries to find the minimum. For example, above, `minimize` started its search at $x = 1.1$ because that's where we told it to start. For the function above, it doesn't really matter what $x$ we start at because the function has only a single global minimum. More technically, the function is [convex](https://en.wikipedia.org/wiki/Convex_function), a property of functions that we will discuss later in the course.\n",
    "\n",
    "Alas, `minimize` isn't perfect. For example, if we give it a function with many valleys (also known as local minima) it can get stuck. For example, consider the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b1d923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w_values = np.linspace(-2, 10, 100)\n",
    "\n",
    "def fw(w):\n",
    "    return 0.1 * w**4 - 1.5*w**3 + 6 * w **2 - 1 * w + 10\n",
    "\n",
    "plt.plot(w_values, fw(w_values));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd0cbacb",
   "metadata": {},
   "source": [
    "If we start the minimization at $w = 6.5$, we'll get stuck in the local minimum at $w = 7.03$. \n",
    "\n",
    "**Note:** No matter what your actual variable is called in your function, the `minimize` routine still calls the starting point `x0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aaf621",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minimize(fw, x0 = 6.5)['x'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9be6be8c",
   "metadata": {},
   "source": [
    "If we start the minimization at $w = 0.5$ or $w=-0.5$, we'll get stuck in the local minimum at $w = 0.08$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c9cf19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minimize(fw, x0 = 0.5)['x'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5de0f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minimize(fw, x0 = -0.5)['x'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e31f0d88",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 7.** Using the `minimize` function, find the value of `theta` that minimizes the mean squared error for our `tips` dataset. In other words, you want to find the exact minimum of the plot that you generated in **Question 5**.\n",
    "\n",
    "Assign `min_sq_scipy` to the value of $\\theta$ that minimizes the MSE according to the `minimize` function.\n",
    "\n",
    "You can't pass your `mean_squared_error` function to `minimize` because `mean_squared_error` has two variables: $\\theta$ and `data`. `minimize` will get confused because it thinks it needs to minimize by picking the best $\\theta$ and best `data` values. We only want it to use $\\theta$.\n",
    "\n",
    "Therefore, you need to pass a function of one variable, $\\theta$, to the `minimize` function. This means you'll need to create a new function of only **one** variable $\\theta$. In practice this is simple, but it can also be very tricky when you do this for the first time. Make sure to ask for help if you get stuck.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7f1581",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_squared_error_with_one_variable(theta):\n",
    "    \"\"\"\n",
    "    Purpose\n",
    "    -------\n",
    "    Calculate the mean square error with one variable\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    theta: A constant representing a summary statistic \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The value of the mean square error.\n",
    "    \"\"\"\n",
    "    ...\n",
    "min_sq_scipy = minimize(..., x0 = 2.5)[...][...] \n",
    "min_sq_scipy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb0ea371",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Reflecting on the lab so far, we've now seen 3 ways to find the summary statistic $\\hat \\theta$ that minimizes the mean squared error:\n",
    "\n",
    "1. Create a plot of the MSE for the given data array vs. $\\theta$ and eyeball the minimizing $\\hat \\theta$.\n",
    "\n",
    "2. Create a function that returns the MSE for a specific data array as a function of $\\theta$ and use the scipy `minimize` function to find the exact $\\hat \\theta$ which minimizes this function.\n",
    "\n",
    "3. Simply compute the `mean` of the data array.\n",
    "\n",
    "At this point, you've hopefully convinced yourself that the `mean` of the data is the summary statistic that minimizes mean squared error."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf9e805a",
   "metadata": {},
   "source": [
    "### Absolute Loss Function \n",
    "\n",
    "$$L\\left(\\theta, y \\right) = \\left| y - \\theta \\right|$$\n",
    "\n",
    "In this section, you will follow the exact same steps as above but for the absolute loss function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4df59eac",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 8.** In the cell below define the function `abs_loss` which returns the absolute loss given a value of $\\theta$ and `y_i`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce214cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def abs_loss(y_i, theta):\n",
    "    \"\"\"\n",
    "    Purpose\n",
    "    -------\n",
    "    Calculate the absolute loss of the observed data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_i: an observed value\n",
    "    theta: A constant representing a summary statistic\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The absolute loss between the observation and the summary statistic\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0e93252",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 9.** Let's now consider the case where `theta` equals 10. For arbitrary values of `y_is`, plot the absolute loss using the function you implemented in the previous question. Don't forget to label your graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80502e81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Our choice for theta\n",
    "theta = ...\n",
    "\n",
    "# Array of values for y_i\n",
    "y_is = np.linspace(0, 20, 100)\n",
    "\n",
    "# Plot\n",
    "plt.xlabel(...)\n",
    "plt.ylabel(...)\n",
    "plt.plot(..., ...);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f6ddaaa",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 10.** Define the `mean_absolute_error` function which computes the mean absolute error given the data as an array and a value for `theta`. \n",
    "\n",
    "**Note:** Assume that `data` will be a `NumPy` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d299539",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_absolute_error(data, theta):\n",
    "    \"\"\"\n",
    "    Purpose\n",
    "    -------\n",
    "    Calculate the mean absolute error\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data:  An array of data values\n",
    "    theta: A constant representing a summary statistic\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The value of the mean absolute error\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "240466d8",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 11.** In the cell below plot the mean absolute error for different $\\theta$ values on the `tips` dataset. You should save your mean absolute error estimates in a list named `mae`.\n",
    "\n",
    "**Note:** The `theta_values` are given. Make sure to label the axes on your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978e5f76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Theta values\n",
    "theta_values = np.linspace(2.7, 3.02, 100\n",
    "\n",
    "# MAE values\n",
    "mae = ... \n",
    "\n",
    "plt.xlabel(r\"Choice for $\\theta$\")\n",
    "plt.ylabel(r\"...\")\n",
    "plt.plot(..., ...);;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba1dfc2c",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "You should see that the plot looks somewhat similar the plot of the mean squared error. However, there are three key differences between the plots of the MSE and MAE.\n",
    "\n",
    "1. The minimizing $\\theta$ is different.\n",
    "\n",
    "2. The plot for MAE increases linearly instead of quadratically as we move far away from the minimizing $\\theta$.\n",
    "\n",
    "3. The plot for MAE is piecewise linear instead of smooth. Each change in slope happens at the same $\\theta$ value as a data point in our dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "575667fb",
   "metadata": {},
   "source": [
    "### Find the Minimizing Value for the Tips Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757dda8f",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c97e5cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_absolute_error_with_one_variable(theta):\n",
    "    \"\"\"\n",
    "    Purpose\n",
    "    -------\n",
    "    Calculate the mean square absolute with one variable\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    theta: A constant representing a summary statistic \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The value of the mean absolute error\n",
    "    \"\"\"\n",
    "    ...\n",
    "min_abs_scipy = minimize(..., x0 = 2.5)[...][...] \n",
    "min_abs_scipy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f5491f2",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Just like the MSE, there are three ways to compute the summary statistic $\\hat \\theta$ that minimizes the MAE:\n",
    "\n",
    "1. Create a plot of the MAE for the given data array vs. $\\theta$ and eyeball a minimizing $\\hat \\theta$.\n",
    "\n",
    "2. Create a function that returns the MAE for a specific data array as a function of $\\theta$ and use the scipy `minimize` function to find an exact $\\hat \\theta$ which minimizes this function.\n",
    "\n",
    "3. Simply compute the median of the data array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514918de",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ee1a84",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a718f412",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(tips)\n244",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.sum(np.round(tips))\n733.0",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(tips, np.ndarray)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
